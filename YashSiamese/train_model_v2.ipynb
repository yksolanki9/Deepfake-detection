{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 128)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "abs_path = \"/scratch/ysolanki/SiameseFacebook/SampleDatasetFromElvin/resize/\"\n",
    "data = np.load(abs_path + \"sample-dataset-elvin-1000rf-faces-embeddings.npz\")\n",
    "trainX, trainY = data['arr_0'], data['arr_1']\n",
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(trainY)\n",
    "# print(le.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 128) (1800,)\n",
      "(200, 128) (200,)\n",
      "[1 0 0 0 1 1 1 0 0 0 1 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 1 0\n",
      " 1 1 1 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1\n",
      " 1 1 0 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 1 1\n",
      " 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 0 1 1 1 0 1 1 0\n",
      " 1 0 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 1 1 1 0 1 0 1 0 1 0 0 0 0 1 1 1 1\n",
      " 0 0 0 1 0 1 1 1 1 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# !pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size=0.1, random_state=5, shuffle = True)\n",
    "\n",
    "print(trainX.shape, trainY.shape)\n",
    "print(testX.shape, testY.shape)\n",
    "print(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_hard_triplet_loss() missing 3 required positional arguments: 'labels', 'embeddings', and 'margin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-68938d7c72aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtriplet_loss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbatch_hard_triplet_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_hard_triplet_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: batch_hard_triplet_loss() missing 3 required positional arguments: 'labels', 'embeddings', and 'margin'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.1, input_shape=(128,)))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(64))\n",
    "\n",
    "#Compile the model\n",
    "\n",
    "from triplet_loss import batch_hard_triplet_loss\n",
    "loss = batch_hard_triplet_loss(labels, embeddings, margin, squared=False)\n",
    "\n",
    "opt = Adam(learning_rate=3e-4)\n",
    "\n",
    "model.compile(loss=batch_hard_triplet_loss, optimizer=opt)\n",
    "\n",
    "#Train the model\n",
    "model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
